{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Scaling \n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "#classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "\n",
    "#metircs to eavlate the model performance\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#libaries for hyperparameter search\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "\n",
    "#oversampling\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "#stats meauseres\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "\n",
    "#basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import *\n",
    "from imblearn.over_sampling import *\n",
    "\n",
    "data=pd.read_csv('/cache/data_selected.csv')\n",
    "data=data.drop('Unnamed: 0',axis=1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(data.iloc[:,:-1],data.iloc[:,-1],test_size=0.2)\n",
    "rf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      8320\n",
      "           1       0.76      1.00      0.87       296\n",
      "\n",
      "    accuracy                           0.99      8616\n",
      "   macro avg       0.88      0.99      0.93      8616\n",
      "weighted avg       0.99      0.99      0.99      8616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_imb,y_imb=c.fit_sample(X_train,y_train)\n",
    "rf.fit(X_imb,y_imb)\n",
    "pred=rf.predict(X_test)\n",
    "print(classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      8319\n",
      "           1       0.77      1.00      0.87       297\n",
      "\n",
      "    accuracy                           0.99      8616\n",
      "   macro avg       0.88      0.99      0.93      8616\n",
      "weighted avg       0.99      0.99      0.99      8616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_imb,y_imb=OneSidedSelection().fit_sample(X_train,y_train)\n",
    "rf.fit(X_imb,y_imb)\n",
    "pred=rf.predict(X_test)\n",
    "print(classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      8303\n",
      "           1       0.77      0.98      0.86       313\n",
      "\n",
      "    accuracy                           0.99      8616\n",
      "   macro avg       0.88      0.98      0.93      8616\n",
      "weighted avg       0.99      0.99      0.99      8616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_imb,y_imb=EditedNearestNeighbours().fit_sample(X_train,y_train)\n",
    "rf.fit(X_imb,y_imb)\n",
    "pred=rf.predict(X_test)\n",
    "print(classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      8320\n",
      "           1       0.76      0.99      0.86       296\n",
      "\n",
      "    accuracy                           0.99      8616\n",
      "   macro avg       0.88      0.99      0.93      8616\n",
      "weighted avg       0.99      0.99      0.99      8616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_imb,y_imb=NeighbourhoodCleaningRule().fit_sample(X_train,y_train)\n",
    "rf.fit(X_imb,y_imb)\n",
    "pred=rf.predict(X_test)\n",
    "print(classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      8085\n",
      "           1       0.85      0.62      0.72       531\n",
      "\n",
      "    accuracy                           0.97      8616\n",
      "   macro avg       0.91      0.81      0.85      8616\n",
      "weighted avg       0.97      0.97      0.97      8616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_imb, y_imb = ADASYN(random_state=0).fit_sample(X_train, y_train)\n",
    "rf.fit(X_imb,y_imb)\n",
    "pred=rf.predict(X_test)\n",
    "print(classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      8156\n",
      "           1       0.83      0.70      0.76       460\n",
      "\n",
      "    accuracy                           0.98      8616\n",
      "   macro avg       0.91      0.84      0.87      8616\n",
      "weighted avg       0.98      0.98      0.98      8616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_imb,y_imb=SMOTE().fit_sample(X_train,y_train)\n",
    "rf.fit(X_imb,y_imb)\n",
    "pred=rf.predict(X_test)\n",
    "print(classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      8019\n",
      "           1       0.87      0.56      0.68       597\n",
      "\n",
      "    accuracy                           0.96      8616\n",
      "   macro avg       0.92      0.78      0.83      8616\n",
      "weighted avg       0.96      0.96      0.96      8616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_imb, y_imb = SMOTEENN(random_state=0).fit_sample(X_train, y_train)\n",
    "rf.fit(X_imb,y_imb)\n",
    "pred=rf.predict(X_test)\n",
    "print(classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import *\n",
    "from imblearn.combine import *\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(data.iloc[:,:-1],data.iloc[:,-1],test_size=0.3)\n",
    "X_imb,y_imb=TomekLinks().fit_sample(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx=MinMaxScaler()\n",
    "lc=LogisticRegression()\n",
    "pipeline=make_pipeline(mx,lc)\n",
    "pipeline.fit(X_imb,y_imb)\n",
    "\n",
    "lr_pred=pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98     12924\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.95     12924\n",
      "   macro avg       0.50      0.48      0.49     12924\n",
      "weighted avg       1.00      0.95      0.98     12924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(lr_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(data.iloc[:,:-1],data.iloc[:,-1],test_size=0.2)\n",
    "X_imb,y_imb=TomekLinks().fit_sample(X_train,y_train)\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start =10, stop = 100, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "rf=RandomForestClassifier()\n",
    "rf_random_search=RandomizedSearchCV(rf,param_distributions=random_grid,n_iter=100,cv=5,verbose=2,scoring='roc_auc')\n",
    "rf_random_search.fit(X_imb,y_imb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the best parameters\n",
    "rf_random_search.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(min_samples_leaf=1,max_depth=None,n_estimators=80,min_samples_split=2)\n",
    "rf.fit(X_imb,y_imb)\n",
    "pred=rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      8312\n",
      "           1       0.76      0.99      0.86       304\n",
      "\n",
      "    accuracy                           0.99      8616\n",
      "   macro avg       0.88      0.99      0.93      8616\n",
      "weighted avg       0.99      0.99      0.99      8616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   14.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('mx',\n",
       "                                              MinMaxScaler(copy=True,\n",
       "                                                           feature_range=(0,\n",
       "                                                                          1))),\n",
       "                                             ('dt',\n",
       "                                              DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                                     class_weight=None,\n",
       "                                                                     criterion='gini',\n",
       "                                                                     max_depth=None,\n",
       "                                                                     max_features=None,\n",
       "                                                                     max_leaf_nodes=None,\n",
       "                                                                     min_impurity_decrease=0.0,\n",
       "                                                                     min_impurity_split=None,\n",
       "                                                                     min_samples_leaf=1,\n",
       "                                                                     min_samples_split=2,\n",
       "                                                                     m...\n",
       "                                                                     splitter='best'))],\n",
       "                                      verbose=False),\n",
       "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'dt__max_depth': [10, 20, 30, 40, 50,\n",
       "                                                          60, 70, 80, 90, 100,\n",
       "                                                          110, None],\n",
       "                                        'dt__min_samples_leaf': [2, 4, 6],\n",
       "                                        'dt__min_samples_split': [2, 5, 10],\n",
       "                                        'dt__splitter': ['best', 'random']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx=MinMaxScaler()\n",
    "dt=DecisionTreeClassifier()\n",
    "splitter=['best','random']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2, 4,6]\n",
    "\n",
    "pipeline=Pipeline([('mx',mx),('dt',dt)])\n",
    "# Create the random grid\n",
    "random_grid = {'dt__splitter': splitter,\n",
    "               'dt__max_depth': max_depth,\n",
    "               'dt__min_samples_split':min_samples_split,\n",
    "               'dt__min_samples_leaf': min_samples_leaf}\n",
    "dt_random_search=RandomizedSearchCV(pipeline,param_distributions=random_grid,n_iter=100,cv=5,n_jobs=-1,verbose=2)\n",
    "dt_random_search.fit(X_imb,y_imb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('mx', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('dt',\n",
       "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                        criterion='gini', max_depth=10,\n",
       "                                        max_features=None, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=6, min_samples_split=5,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort='deprecated', random_state=None,\n",
       "                                        splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=DecisionTreeClassifier(criterion='gini',max_depth=10,min_samples_leaf=6,min_samples_split=5,splitter='best')\n",
    "dt.fit(X_imb,y_imb)\n",
    "dt_pred=dt.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     12465\n",
      "           1       0.71      0.91      0.80       459\n",
      "\n",
      "    accuracy                           0.98     12924\n",
      "   macro avg       0.85      0.95      0.89     12924\n",
      "weighted avg       0.99      0.98      0.98     12924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dt_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 24 is smaller than n_iter=100. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('mx',\n",
       "                                              MinMaxScaler(copy=True,\n",
       "                                                           feature_range=(0,\n",
       "                                                                          1))),\n",
       "                                             ('KNN',\n",
       "                                              KNeighborsClassifier(algorithm='auto',\n",
       "                                                                   leaf_size=30,\n",
       "                                                                   metric='minkowski',\n",
       "                                                                   metric_params=None,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   n_neighbors=5,\n",
       "                                                                   p=2,\n",
       "                                                                   weights='uniform'))],\n",
       "                                      verbose=False),\n",
       "                   iid='deprecated', n_iter=100, n_jobs=None,\n",
       "                   param_distributions={'KNN__algorithm': ['auto', 'kd_tree'],\n",
       "                                        'KNN__leaf_size': [1, 3, 5],\n",
       "                                        'KNN__n_jobs': [-1],\n",
       "                                        'KNN__n_neighbors': [4, 5, 6, 7]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx=MinMaxScaler()\n",
    "KNN=KNeighborsClassifier()\n",
    "pipeline=Pipeline([('mx',mx),('KNN',KNN)])\n",
    "parameters = {'KNN__n_neighbors':[4,5,6,7],\n",
    "              'KNN__leaf_size':[1,3,5],\n",
    "              'KNN__algorithm':['auto', 'kd_tree'],\n",
    "              'KNN__n_jobs':[-1]}\n",
    "knn_random_search=RandomizedSearchCV(pipeline,param_distributions=parameters,cv=5,n_iter=100)\n",
    "knn_random_search.fit(X_imb,y_imb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('mx', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('KNN',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_random_search.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN=KNeighborsClassifier(algorithm='auto',leaf_size=30,metric='minkowski',n_neighbors=5,p=2,weights='uniform')\n",
    "pipeline=Pipeline([('mx',mx),('KNN',KNN)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_re,y_re)\n",
    "X_test_scaled=mx.fit_transform(X_test)\n",
    "pred=pipeline.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     12924\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.95     12924\n",
      "   macro avg       0.50      0.48      0.49     12924\n",
      "weighted avg       1.00      0.95      0.97     12924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx=MinMaxScaler()\n",
    "ada=AdaBoostClassifier()\n",
    "pipeline=Pipeline([('mx',mx),('ada',ada)])\n",
    "n_estimator=[int(x) for x in np.linspace(100,200,10)]\n",
    "learning_rate=[ x  for x in np.linspace(0.01,1,10)]\n",
    "params={'ada__n_estimators':n_estimator,\n",
    "        'ada__learning_rate':learning_rate}\n",
    "ada_random_search=RandomizedSearchCV(pipeline,param_distributions=params,cv=5,n_iter=100,n_jobs=-1)\n",
    "ada_random_search.fit(X_imb,y_imb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_random_search.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada=AdaBoostClassifier(algorithm='SAMME.R',base_estimator=None,learning_rate=1.0,n_estimators=50)\n",
    "ada.fit(X_imb,y_imb)\n",
    "pred=ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     12495\n",
      "           1       0.70      0.96      0.81       429\n",
      "\n",
      "    accuracy                           0.99     12924\n",
      "   macro avg       0.85      0.97      0.90     12924\n",
      "weighted avg       0.99      0.99      0.99     12924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Light GBM\n",
    "\n",
    "It is highly recommendable to specify the early stopping criterios to avoid unwanted overfitting problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8616"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(data.iloc[:,:-1],data.iloc[:,-1],test_size=0.2)\n",
    "X_imb,y_imb=TomekLinks().fit_sample(X_train,y_train)\n",
    "len(X_test)\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter Sets\n",
    "param_test={'num_leaves':np.arange(6,51),\n",
    "            'min_child_samples':np.arange(100,601),\n",
    "            'min_child_weight':[1e-5,1e-3,1e-2,1e-1,1,1e1,1e2,1e3,1e4],\n",
    "            'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "            'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "\n",
    "#Prepare the fit_params specifying the early stopping criterion\n",
    "fit_params={'early_stopping_rounds':[100],\n",
    "            'eval_metric':'auc',\n",
    "            'eval_set':[(X_test,y_test)],\n",
    "            'eval_names':['valid'],\n",
    "            'verbose':[100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg=lgb.LGBMClassifier(max_depth=-1,random_state=322,silent=True,metric='None',n_estimators=5000)\n",
    "lg_search=RandomizedSearchCV(estimator=lg,param_distributions=fit_params,n_iter=100,scoring='roc_auc',cv=5,refit=True,random_state=314,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 3 is smaller than n_iter=100. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid's auc: 0.993631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid's auc: 0.993087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid's auc: 0.99432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[472]\tvalid's auc: 0.994472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid's auc: 0.993849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid's auc: 0.993631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid's auc: 0.993087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid's auc: 0.99432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[472]\tvalid's auc: 0.994472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid's auc: 0.993849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid's auc: 0.993631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid's auc: 0.993087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid's auc: 0.99432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[472]\tvalid's auc: 0.994472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid's auc: 0.993849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   39.5s finished\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[515]\tvalid's auc: 0.994279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=LGBMClassifier(boosting_type='gbdt',\n",
       "                                            class_weight=None,\n",
       "                                            colsample_bytree=1.0,\n",
       "                                            importance_type='split',\n",
       "                                            learning_rate=0.1, max_depth=-1,\n",
       "                                            metric='None', min_child_samples=20,\n",
       "                                            min_child_weight=0.001,\n",
       "                                            min_split_gain=0.0,\n",
       "                                            n_estimators=5000, n_jobs=-1,\n",
       "                                            num_leaves=31, objective=None,\n",
       "                                            random_state=322, reg_alpha=0.0,\n",
       "                                            reg_l...\n",
       "197     0.611200   0.794580  0.000000  \n",
       "...          ...        ...       ...  \n",
       "22837   0.156900   1.030100  0.175390  \n",
       "7112    5.554395  31.488616  0.000000  \n",
       "29569   0.695390   0.974580  0.162690  \n",
       "26442   1.526000   0.815220  0.000000  \n",
       "26262   0.822250   0.983420  0.733720  \n",
       "\n",
       "[8616 rows x 9 columns],\n",
       "                                                      array([0, 0, 1, ..., 0, 0, 0], dtype=int64))],\n",
       "                                        'verbose': [100]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=314, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=True)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_search.fit(X_imb,y_imb,**fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               early_stopping_rounds=100, eval_metric='a', eval_names='valid',\n",
       "               eval_set=(          Attr5   Attr21    Attr24     Attr27     Attr34      Attr37  \\\n",
       "7416    -26.438  1.08650  0.525410    1.29440   0.537550  106.160000   \n",
       "29199    44.573  0.94494  0.310980    2.57590   0.530430    9.500500   \n",
       "30888   107.140  0.63056 -0.581730   -2.74910  29.473000   63.985657   \n",
       "8542    -13.545  1.1...\n",
       "                         array([0, 0, 1, ..., 0, 0, 0], dtype=int64)),\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               metric='None', min_child_samples=20, min_child_weight=0.001,\n",
       "               min_split_gain=0.0, n_estimators=5000, n_jobs=-1, num_leaves=31,\n",
       "               objective=None, random_state=322, reg_alpha=0.0, reg_lambda=0.0,\n",
       "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "               subsample_freq=0, verbose=100)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal={'importance_type':'split','learning_rate':0.1,'max_depth':-1,'min_child_samples':20,'min_child_weight':0.001,\n",
    "         'n_jobs':-1,'min_split_gain':0.0,'subsample':1.0,'subsample_for_bin':200000,'n_estimators':5000,'num_leaves':31,'reg_alpha':0.0,'reg_lambda':0.0,'subsample':1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 3 is smaller than n_iter=100. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid's auc: 0.993631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid's auc: 0.993087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid's auc: 0.99432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[472]\tvalid's auc: 0.994472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid's auc: 0.993849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid's auc: 0.993631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid's auc: 0.993087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid's auc: 0.99432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[472]\tvalid's auc: 0.994472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid's auc: 0.993849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid's auc: 0.993631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid's auc: 0.993087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid's auc: 0.99432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[472]\tvalid's auc: 0.994472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid's auc: 0.993849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   42.1s finished\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[515]\tvalid's auc: 0.994279\n"
     ]
    }
   ],
   "source": [
    "lg=lgb.LGBMClassifier(*optimal)\n",
    "lg_search.fit(X_imb,y_imb,**fit_params)\n",
    "lg_pred=lg_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      8256\n",
      "           1       0.85      0.97      0.90       360\n",
      "\n",
      "    accuracy                           0.99      8616\n",
      "   macro avg       0.92      0.98      0.95      8616\n",
      "weighted avg       0.99      0.99      0.99      8616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(lg_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9808462532299742"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(lg_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
